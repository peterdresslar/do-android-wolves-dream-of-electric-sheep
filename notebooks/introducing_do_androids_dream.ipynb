{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Android Wolves Dream of Electric Sheep?\n",
    "\n",
    "### A demonstration of the Artificial Agent Based Model\n",
    "\n",
    "This notebook demonstrates the operation of our agent based model using various AI-based and non AI-based approaches.\n",
    "\n",
    "We will demonstrate the operation of a standard Lotka-Volterra system of predators and prey, using wolves and sheep as the hypothetical animals.\n",
    "\n",
    "While Lotka-Volterra is sensitive as a system to over-predation by the \"wolves\" and collapse of the \"sheep\" (and thus wolves),\n",
    "in the real world predators might prevent these collapses by \"guarding their territory\" and substituting some of\n",
    "their prey-hunting time and energy with aggression toward other predators. In our version of Lotka Volterra, we model\n",
    "this territorial behavior as $\\theta$ (*theta*).\n",
    "\n",
    "But, how can we capture the dynamic application of this variable to the system in a way that best emulates what a wolf would do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "# Fix the import path\n",
    "from model.model import run\n",
    "\n",
    "# Here are the available parameters you can set:\n",
    "#\n",
    "# Core simulation parameters:\n",
    "# - steps: Number of simulation steps to run (default: 250)\n",
    "# - dt: Time step size (default: 0.02)\n",
    "# - s_start: Initial sheep population (default: 100)\n",
    "# - w_start: Initial wolf population (default: 10)\n",
    "# - sheep_max: Maximum sheep capacity (default: 110)\n",
    "#\n",
    "# Wolf behavior parameters:\n",
    "# - no_ai: If True, wolves use fixed theta; if False, wolves use AI (default: False)\n",
    "# - prompt_type: \"high\", \"medium\" or \"low\" (default: \"high\")... amount of information provided to the wolves\n",
    "# - theta_star: Default theta value when no_ai=True (default: 0.5)\n",
    "# - churn_rate: Percentage of wolves that update their theta each step (default: 0.05)\n",
    "# - threads: Number of parallel LLM calls when using async mode (default: 5)\n",
    "#\n",
    "# Wolf population dynamics parameters:\n",
    "# - beta: Predation rate (default: 0.1)\n",
    "# - gamma: Wolf death rate (default: 1.5)\n",
    "# - delta: Conversion efficiency (default: 0.75)\n",
    "#\n",
    "# Sheep population dynamics parameters:\n",
    "# - alpha: Sheep growth rate (default: 1)\n",
    "# - eps: Small value to prevent extinction (default: 0.0001)\n",
    "#\n",
    "# Output parameters:\n",
    "# - save_results: Whether to save simulation results (default: True)\n",
    "# - path: Directory to save results (default: \"../data/results\")\n",
    "\n",
    "# NOTE: Do not set `no_ai` or `prompt_type` or `theta_star` or `steps` here,\n",
    "#  ... they will be set in the calls below\n",
    "\n",
    "my_args = {\n",
    "        \"model_name\": \"gpt-4o-mini\",\n",
    "        \"temperature\": 0.2,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"churn_rate\": 0.1,\n",
    "        \"dt\": 0.02,\n",
    "        \"sheep_max\": 110,\n",
    "        \"eps\": 0.0001,\n",
    "        \"alpha\": 1,\n",
    "        \"beta\": 0.1,\n",
    "        \"gamma\": 1.5,\n",
    "        \"delta\": 0.75,\n",
    "        \"s_start\": 100,\n",
    "        \"w_start\": 10,\n",
    "        \"step_print\": False,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional Wolves (no_ai)\n",
    "\n",
    "### Theta as a constant.\n",
    "\n",
    "In the following examples, we look at $\\theta$ as a constant value that modifies the base LV functions. For review, those are:\n",
    "\n",
    "Standard Lotka-Volterra differential equations:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{ds}{dt} &= \\alpha s - \\beta sw \\\\\n",
    "\\frac{dw}{dt} &= -\\gamma w + \\delta\\beta sw\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We can insert our new variable, theta, as a factor on the equations to modify the impact of predation on the population. So:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{ds}{dt} &= \\alpha s - \\theta\\beta sw \\\\\n",
    "\\frac{dw}{dt} &= -\\gamma w + \\delta\\theta\\beta sw\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In our implementation we can supply a theta value, which we set as $\\theta^*$ or `theta_star` if we want the value to remain constant over the course of the run.\n",
    "\n",
    "We can see from the equations above that if we apply a $\\theta^*$ of 1, the outcome is as if the variable isnÊ»t even there: we get our \"base\" Lotka-Volterra behavior:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model with no_ai=True (note the correct keyword argument syntax)\n",
    "results = run(\n",
    "    **my_args,\n",
    "    theta_star=1,\n",
    "    steps=200,\n",
    "    no_ai=True,\n",
    "    save_results=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a base Lotka-Volterra system output as we would expect. Note that the wolf population is made up of individual \"agents\" in our implementation, so the population graph for the wolves is \"blocky.\" It moves in steps, unlike the sheep population.\n",
    "\n",
    "The crash to zero is a standard outcome for the textbook LV system with the variables we used to start (10 wolves, 100 sheep.) And, again, remember, we have theta set in this version of the system--it is just that at 1, it appears invisible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try setting theta as 0 instead... In this case, our wolves do not eat. They starve. Another population collapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model with no_ai=True (note the correct keyword argument syntax)\n",
    "results = run(\n",
    "    **my_args,\n",
    "    theta_star=0,\n",
    "    steps=200,\n",
    "    no_ai=True,\n",
    "    save_results=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can try a value in between:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model with no_ai=True (note the correct keyword argument syntax)\n",
    "results = run(\n",
    "    **my_args,\n",
    "    theta_star=0.5,\n",
    "    steps=5001,\n",
    "    no_ai=True,\n",
    "    save_results=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, theta_star = 0.5 works as a great stabilizer for our model over very many cycles, with our default model values, anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional Wolves (no_ai)\n",
    "\n",
    "### Theta as a programmed variable.\n",
    "\n",
    "In this example, no AIs are used for setting theta, but it has a variable value. Instead, we rely on a function that is sensitive to the populations of sheep and wolves.\n",
    "\n",
    "Hinting at a function takes us to a very important point. In The Subliminal Wolf (herein TSW), we implemented a basic $\\theta$ variable, but it had to be implemented as a function to be sensitive to scarcity in ways that LV (and thus wolves!) are not. There are examples of settings for the function in TSW that give us a feeling for how a dynamically-set $\\theta$ will work with our population dynamics. \n",
    "\n",
    "For instance:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\theta(s) = \\frac{1}{1 + k\\frac{s_0}{s + \\varepsilon}} \\text{ for some constant } k > 0. \\tag{3}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The above describes one possible functioning of a theta factor that is sensitive to prey scarcity. When combined with our \"modified\" LV above (both lines (1) and (2)), it can yield modified behavior that for specific values will stablize the overall population. This should work for k = 1 with default model settings. k is a sensitivity factor. However, different values of dt (different stepping \"rythyms\") could cause k = 1 to not be an effective stablizing value for the function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model with no_ai=True (note the correct keyword argument syntax)\n",
    "results = run(\n",
    "    **my_args,\n",
    "    k = 1,\n",
    "    steps=5001,\n",
    "    no_ai=True,\n",
    "    save_results=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a nicely-modulating function, although, again, may not be fully stabilizing for every starting state of the model variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI (LLM) Decision Emulating Wolves\n",
    "\n",
    "What if, instead of using a constant theta value, or a function, we wanted to use a more \"organic\" approach to setting the degree of competitiveness displayed\n",
    "by our predators? It turns out that we can emulate this very thing---that is, we can generate results based on a system that attempts to act like a wolf.\n",
    "We can do this by using AI Large Language Models (LLM). In this example we will focus on one specific LLM, ChatGPT 4o, but we could use many other models that exist.\n",
    "\n",
    "## High Information AI Wolves\n",
    "\n",
    "In the following simulation, we prompt the LLMs with a comprehensive view of the scenario and model conditions at each prompt. We explain what the settings of theta will do to the environment generally, but we do not give quantitative advice outside of requiring an output between 0 and 1. We suggest detailed scenario dynamics and how they might be handled, although again the advice is qualitative and not quantitative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model with AI-enabled wolves\n",
    "ai_results = run(\n",
    "    **my_args,\n",
    "    no_ai=False,\n",
    "    steps=5001,\n",
    "    save_results=True,\n",
    "    prompt_type=\"high\"\n",
    ")\n",
    "\n",
    "# Print some information about the results\n",
    "print(f\"Final sheep population: {ai_results['sheep_history'][-1]}\")\n",
    "print(f\"Final wolf population: {ai_results['wolf_history'][-1]}\")\n",
    "print(f\"Thetas: {ai_results['average_theta_history']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medium Information Wolves\n",
    "\n",
    "In the following simulation, we prompt the LLMs with a comprehensive view of the scenario and model conditions at each prompt. We explain what the settings of theta will do to the environment generally, but we do not give quantitative advice outside of requiring an output between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model with AI-enabled wolves\n",
    "ai_results_low = run(\n",
    "    **my_args,\n",
    "    no_ai=False,\n",
    "    steps=5001,\n",
    "    save_results=True,\n",
    "    prompt_type=\"medium\"\n",
    ")\n",
    "\n",
    "# Print some information about the results\n",
    "print(f\"Final sheep population: {ai_results_low['sheep_history'][-1]}\")\n",
    "print(f\"Final wolf population: {ai_results_low['wolf_history'][-1]}\")\n",
    "print(f\"Thetas: {ai_results_low['average_theta_history']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Information AI Wolves\n",
    "\n",
    "In the following demonstration, we prompt the LLMs with a very basic amount of information about the scenario and the current conditions. We explain how high and low theta work to indicate aggression levels. We ask for a value between 0 and 1; no other quantitative advice is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model with AI-enabled wolves\n",
    "ai_results_low = run(\n",
    "    **my_args,\n",
    "    no_ai=False,\n",
    "    steps=5001,\n",
    "    save_results=True,\n",
    "    prompt_type=\"low\"\n",
    ")\n",
    "\n",
    "# Print some information about the results\n",
    "print(f\"Final sheep population: {ai_results_low['sheep_history'][-1]}\")\n",
    "print(f\"Final wolf population: {ai_results_low['wolf_history'][-1]}\")\n",
    "print(f\"Thetas: {ai_results_low['average_theta_history']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
