{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "# Fix the import path\n",
    "from model.model import run\n",
    "\n",
    "# NOTE: Do not set `no_ai` or `prompt_type` or `theta_star` or `steps` here,\n",
    "#  ... they will be set in the calls below\n",
    "\n",
    "my_args = {\n",
    "        # \"model_name\": \"claude-3-5-haiku\",\n",
    "        \"model_name\": \"gpt-4o-mini\",\n",
    "        \"temperature\": 0.2,\n",
    "        \"max_tokens\": 512,\n",
    "        \"churn_rate\": 0.1,\n",
    "        \"dt\": .1,\n",
    "        \"sheep_max\": 1000,\n",
    "        \"eps\": 0.0001,\n",
    "        \"alpha\": 1,\n",
    "        \"beta\": 0.1,\n",
    "        \"gamma\": 1.5,\n",
    "        \"delta\": 0.75,\n",
    "        \"s_start\": 14,\n",
    "        \"w_start\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'set' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run model with AI-enabled wolves\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ai_results \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmy_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_ai\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_print\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/do-android-wolves-dream-of-electric-sheep/model/model.py:348\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m    Run the model synchronously and return the results.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m    This will fail in contexts that already have an event loop running.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;66;03m# Initialize the utils environment\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     initialize_utils()\n",
      "File \u001b[0;32m~/Workspace/do-android-wolves-dream-of-electric-sheep/model/model.py:87\u001b[0m, in \u001b[0;36minitialize_model\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m defaults\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Extract domain and agent parameters\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m sheep_capacity \u001b[38;5;241m=\u001b[39m \u001b[43mdefaults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msheep_max\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m starting_sheep \u001b[38;5;241m=\u001b[39m defaults\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m starting_wolves \u001b[38;5;241m=\u001b[39m defaults\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw_start\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     91\u001b[0m )  \u001b[38;5;66;03m# Add default value for starting_wolves\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'set' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# Run model with AI-enabled wolves\n",
    "ai_results = run(\n",
    "    **my_args,\n",
    "    no_ai=False,\n",
    "    steps=2,\n",
    "    save_results=True,\n",
    "    prompt_type=\"low\",\n",
    "    step_print=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "ChatCompletion(id='chatcmpl-B9EmGEufSurnFEASnCPrlY2M80uhB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='This is a test. How can I assist you further?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1741541456, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_06737a9306', usage=CompletionUsage(completion_tokens=13, prompt_tokens=12, total_tokens=25, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Get the project root directory (assuming notebook is in a notebooks folder)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Load .env from project root\n",
    "load_dotenv(os.path.join(project_root, '.env.local'))\n",
    "\n",
    "print(os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "try:\n",
    "    response = client.chat.completions.with_raw_response.create(\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say this is a test\",\n",
    "        }],\n",
    "        model=\"gpt-4o-mini\",\n",
    "    )\n",
    "    completion = response.parse()\n",
    "    print(completion)\n",
    "\n",
    "except RateLimitError as e:\n",
    "# Access headers from the error response\n",
    "    if hasattr(e, 'response') and hasattr(e.response, 'headers'):\n",
    "        print(\"Rate limit headers from error:\")\n",
    "        print(f\"x-ratelimit-limit-tokens: {e.response.headers.get('x-ratelimit-limit-tokens')}\")\n",
    "        print(f\"x-ratelimit-remaining-tokens: {e.response.headers.get('x-ratelimit-remaining-tokens')}\")\n",
    "        print(f\"x-ratelimit-reset-tokens: {e.response.headers.get('x-ratelimit-reset-tokens')}\")\n",
    "\n",
    "    # Print the error details\n",
    "    print(f\"Error type: {e.__class__.__name__}\")\n",
    "    print(f\"Error message: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
